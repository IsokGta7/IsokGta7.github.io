<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Reconocimiento Facial</title>

    <!-- CSS Dependencies (Materialize) -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            background-color: #f9f9f9;
        }

        h1 {
            margin-bottom: 20px;
        }

        .video-preview-container {
            position: relative;
            margin-bottom: 20px;
        }

        canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
    </style>

    <!-- JS Dependencies (jQuery and Materialize) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.4/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/js/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script> <!-- TensorFlow.js -->
    <script
        src="https://cdn.jsdelivr.net/gh/Justineo/tfjs-face-recognition@latest/dist/tfjs-face-recognition.min.js"></script>
    <!-- modelo de reconocimiento facial -->
</head>

<body>

    <h1>Reconocimiento Facial</h1>

    <div class="video-preview-container">
        <video id="webcam_feed" autoplay playsinline width="320" height="240" style="display:none;"></video>
        <canvas id="realTimeCanvas" width="320" height="240"></canvas>
    </div>

    <div class="objno"></div>

    <button class="btn-large" onclick="showWebcam()">Iniciar Reconocimiento Facial</button>

    <script>
        $(document).ready(function () {
            $('.modal').modal({ dismissible: false });

            const videoWidth = 320;
            const videoHeight = 240;
            const fpsLimit = 10;

            const videoCanvas = document.querySelector("#realTimeCanvas");
            const rtCtx = videoCanvas.getContext("2d");

            let yolo_rt = null;
            let video = null;

            // Función para mostrar la cámara web
            window.showWebcam = function () {
                const video = document.querySelector("#webcam_feed");
                let intervalId;

                if (navigator.mediaDevices.getUserMedia) {
                    navigator.mediaDevices.getUserMedia({
                        video: {
                            width: videoWidth,
                            height: videoHeight
                        }
                    })
                        .then(function (stream) {
                            video.srcObject = stream;
                            video.play();

                            // Inicializa el reconocimiento facial
                            initializeFaceRecognition(video);
                        })
                        .catch(function (err) {
                            console.error("Error al acceder a la cámara: ", err);
                            M.toast({
                                html: 'Error al acceder a la cámara',
                                displayLength: 3000,
                                classes: 'rounded red'
                            });
                        });
                } else {
                    console.error("getUserMedia no soportado");
                    M.toast({
                        html: 'Error: Navegador no soportado',
                        displayLength: 3000,
                        classes: 'rounded red'
                    });
                }
            };

            async function initializeFaceRecognition(video) {
                // Cargar el modelo de reconocimiento facial
                yolo_rt = await tf.loadGraphModel('/eirodriguezt/assets/faces/model.json'); // Asegúrate de usar la URL del modelo

                // Inicia el intervalo para detección
                setInterval(() => detectFaces(video), 1000 / fpsLimit);
                M.toast({
                    html: 'Modelo de reconocimiento facial cargado',
                    displayLength: 1000,
                    classes: 'rounded green'
                });
            }

            async function detectFaces(video) {
                rtCtx.drawImage(video, 0, 0, videoCanvas.width, videoCanvas.height);

                // Preprocesar la imagen para la detección 
                const inputTensor = tf.browser.fromPixels(videoCanvas).expandDims(0).toFloat();
                const predictions = await yolo_rt.executeAsync(inputTensor);

                processResults(predictions);
            }

            function processResults(results) {
                rtCtx.clearRect(0, 0, videoCanvas.width, videoCanvas.height);
                rtCtx.drawImage(video, 0, 0, videoCanvas.width, videoCanvas.height);

                results.forEach(result => {
                    const x = result.x * videoCanvas.width;
                    const y = result.y * videoCanvas.height;
                    const w = result.w * videoCanvas.width;
                    const h = result.h * videoCanvas.height;
                    const label = `Reconocido`;
                    drawRectangle(rtCtx, y, x, w, h, label);
                });

                $('.objno').text('Reconocimiento en curso.'); // Mensaje en tiempo real
            }

            function drawRectangle(ctx, y, x, w, h, lbl) {
                ctx.beginPath();
                ctx.rect(x, y, w, h);
                ctx.lineWidth = 2;
                ctx.strokeStyle = 'red';
                ctx.stroke();
                ctx.font = '16px Arial';
                ctx.fillStyle = 'green';
                ctx.fillText(lbl, x, y > 20 ? y - 10 : 20);
            }
        });
    </script>

</body>

</html>