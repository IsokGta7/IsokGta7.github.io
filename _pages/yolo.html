---
layout: default
title: Detección de objetos YOLO
description: Inferencia en navegador con modelo YOLOv8 optimizado en TensorFlow.js.
permalink: /yolo/
---

<section class="demo-card">
  <div class="section-title">
    <div>
      <p class="eyebrow" data-i18n-en="YOLOv8 · Vision">YOLOv8 · Visión</p>
      <h2 data-i18n-en="Live object detection">Detección de objetos en vivo</h2>
      <p class="subtle-text" data-i18n-en="Light stream at 640x640 with non-max suppression and dynamic scaling.">Stream ligero a 640x640 con supresión no máxima y escalado dinámico.</p>
    </div>
    <span id="yolo-status" class="status-pill" data-i18n-en="Loading model...">Cargando modelo...</span>
  </div>

  <div class="summary-grid">
    <div class="summary-card">
      <h3 data-i18n-en="How it works">Cómo funciona</h3>
      <ul>
        <li data-i18n-en="Resizes camera frames to 640x640 and normalizes pixels.">Redimensiona frames de cámara a 640x640 y normaliza píxeles.</li>
        <li data-i18n-en="Runs YOLOv8 in WebGL and gets boxes plus classes.">Ejecuta el modelo YOLOv8 en WebGL y obtiene cajas + clases.</li>
        <li data-i18n-en="Applies non-max suppression and draws overlays on canvas.">Aplica supresión no máxima y dibuja overlays en canvas.</li>
      </ul>
    </div>
    <div class="summary-card">
      <h3 data-i18n-en="Recommendations">Recomendaciones</h3>
      <ul>
        <li data-i18n-en="Use good lighting and avoid sudden movement.">Usa buena iluminación y evita movimiento brusco.</li>
        <li data-i18n-en="If performance drops, lower the device camera resolution.">Si el rendimiento baja, reduce la resolución de la cámara del dispositivo.</li>
        <li data-i18n-en="Stop detection before switching tabs to free GPU.">Detén la detección antes de cambiar de pestaña para liberar GPU.</li>
      </ul>
    </div>
  </div>

  <div class="controls">
    <button id="yolo-start" class="button" data-i18n-en="Start detection">Iniciar detección</button>
    <button id="yolo-stop" class="button secondary" disabled data-i18n-en="Stop">Detener</button>
  </div>

  <div class="video-panel">
    <div class="media-wrapper">
      <video id="yolo-video" autoplay playsinline muted width="640" height="480"></video>
      <canvas id="yolo-canvas" class="overlay-canvas"></canvas>
    </div>
    <p class="subtle-text" data-i18n-en="Enable the camera and watch detections.">Activa la cámara y observa las detecciones.</p>
  </div>
</section>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"></script>
<script>
  document.addEventListener('DOMContentLoaded', () => {
    const video = document.getElementById('yolo-video');
    const canvas = document.getElementById('yolo-canvas');
    const statusPill = document.getElementById('yolo-status');
    const startBtn = document.getElementById('yolo-start');
    const stopBtn = document.getElementById('yolo-stop');

    const TARGET = 640;
    let model;
    let stream;
    let rafId;
    let statusKey = 'loading';
    let statusState = '';
    let videoWidth = 0;
    let videoHeight = 0;
    let displayWidth = 0;
    let displayHeight = 0;
    let deviceScale = 1;
    let inputScale = 1;
    let padLeft = 0;
    let padTop = 0;
    let padRight = 0;
    let padBottom = 0;

    const copy = {
      status: {
        loading: { es: 'Cargando modelo...', en: 'Loading model...' },
        ready: { es: 'Modelo listo', en: 'Model ready' },
        cameraError: { es: 'Permiso de cámara requerido', en: 'Camera permission required' },
        error: { es: 'Error al cargar modelo', en: 'Error loading model' }
      }
    };

    const classNames = {
      0: "person", 1: "bicycle", 2: "car", 3: "motorcycle", 4: "airplane", 5: "bus", 6: "train", 7: "truck",
      8: "boat", 9: "traffic light", 10: "fire hydrant", 11: "stop sign", 12: "parking meter", 13: "bench",
      14: "bird", 15: "cat", 16: "dog", 17: "horse", 18: "sheep", 19: "cow", 20: "elephant", 21: "bear",
      22: "zebra", 23: "giraffe", 24: "backpack", 25: "umbrella", 26: "handbag", 27: "tie", 28: "suitcase",
      29: "frisbee", 30: "skis", 31: "snowboard", 32: "sports ball", 33: "kite", 34: "baseball bat",
      35: "baseball glove", 36: "skateboard", 37: "surfboard", 38: "tennis racket", 39: "bottle",
      40: "wine glass", 41: "cup", 42: "fork", 43: "knife", 44: "spoon", 45: "bowl", 46: "banana",
      47: "apple", 48: "sandwich", 49: "orange", 50: "broccoli", 51: "carrot", 52: "hot dog", 53: "pizza",
      54: "donut", 55: "cake", 56: "chair", 57: "couch", 58: "potted plant", 59: "bed", 60: "dining table",
      61: "toilet", 62: "tv", 63: "laptop", 64: "mouse", 65: "remote", 66: "keyboard", 67: "cell phone",
      68: "microwave", 69: "oven", 70: "toaster", 71: "sink", 72: "refrigerator", 73: "book", 74: "clock",
      75: "vase", 76: "scissors", 77: "teddy bear", 78: "hair drier", 79: "toothbrush"
    };

    function translate(map) {
      return (window.SiteI18n && window.SiteI18n.translate) ? window.SiteI18n.translate(map) : (map?.es || '');
    }

    function setStatus(key, state = '') {
      statusKey = key;
      statusState = state;
      const text = translate(copy.status[key] || { es: key, en: key });
      statusPill.textContent = text;
      statusPill.className = `status-pill ${state}`.trim();
    }

    async function loadModel() {
      try {
        await tf.ready();
        await tf.setBackend('webgl');
        model = await tf.loadGraphModel('{{ '/assets/YOLO/YOLO_model.json' | relative_url }}');
        setStatus('ready', 'ready');
      } catch (error) {
        console.error(error);
        setStatus('error', 'error');
      }
    }

    function updateVideoMetrics() {
      if (!video.videoWidth || !video.videoHeight) return false;
      const hasChanged = video.videoWidth !== videoWidth || video.videoHeight !== videoHeight;
      videoWidth = video.videoWidth;
      videoHeight = video.videoHeight;

      inputScale = Math.min(TARGET / videoWidth, TARGET / videoHeight);
      const scaledWidth = Math.round(videoWidth * inputScale);
      const scaledHeight = Math.round(videoHeight * inputScale);
      const padX = TARGET - scaledWidth;
      const padY = TARGET - scaledHeight;
      padLeft = Math.floor(padX / 2);
      padRight = padX - padLeft;
      padTop = Math.floor(padY / 2);
      padBottom = padY - padTop;
      return hasChanged;
    }

    function syncCanvasToVideo() {
      const rect = video.getBoundingClientRect();
      if (!rect.width || !rect.height) return false;

      displayWidth = rect.width;
      displayHeight = rect.height;
      deviceScale = window.devicePixelRatio || 1;

      const scaledWidth = Math.round(displayWidth * deviceScale);
      const scaledHeight = Math.round(displayHeight * deviceScale);

      canvas.style.width = `${displayWidth}px`;
      canvas.style.height = `${displayHeight}px`;
      if (canvas.width !== scaledWidth || canvas.height !== scaledHeight) {
        canvas.width = scaledWidth;
        canvas.height = scaledHeight;
        return true;
      }
      return false;
    }

    function stopDetection() {
      if (rafId) cancelAnimationFrame(rafId);
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        stream = null;
      }
      video.srcObject = null;
      startBtn.disabled = false;
      stopBtn.disabled = true;
    }

    async function startDetection() {
      if (!model) await loadModel();
      stopDetection();
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: { ideal: 'environment' } } });
        video.srcObject = stream;
        startBtn.disabled = true;
        stopBtn.disabled = false;
        requestAnimationFrame(syncCanvasToVideo);
        renderLoop();
      } catch (error) {
        console.error('Camera permission needed', error);
        setStatus('cameraError', 'error');
      }
    }

    function preprocessFrame() {
      if (!videoWidth || !videoHeight) updateVideoMetrics();
      return tf.tidy(() => {
        const frame = tf.browser.fromPixels(video);
        const targetWidth = Math.round(videoWidth * inputScale);
        const targetHeight = Math.round(videoHeight * inputScale);
        const resized = tf.image.resizeBilinear(frame, [targetHeight, targetWidth]);
        const padded = tf.pad(resized, [[padTop, TARGET - targetHeight - padTop], [padLeft, TARGET - targetWidth - padLeft], [0, 0]]);
        const normalized = padded.div(255.0);
        return normalized.expandDims(0);
      });
    }

    function drawDetections(detections) {
      if (!displayWidth || !displayHeight) return;
      const ctx = canvas.getContext('2d');
      ctx.setTransform(1, 0, 0, 1, 0, 0);
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.setTransform(deviceScale, 0, 0, deviceScale, 0, 0);
      ctx.strokeStyle = '#22d3ee';
      ctx.lineWidth = 2 / deviceScale;
      ctx.font = `${14 / deviceScale}px Inter`;
      ctx.fillStyle = 'rgba(17, 94, 89, 0.8)';

      detections.forEach(det => {
        const [x, y, w, h, score, classId] = det;
        ctx.strokeRect(x, y, w, h);
        const label = `${classNames[classId]} ${(score * 100).toFixed(1)}%`;
        const textWidth = ctx.measureText(label).width;
        ctx.fillRect(x, y - 18, textWidth + 8, 20);
        ctx.fillStyle = '#0b1222';
        ctx.fillText(label, x + 4, y - 4);
        ctx.fillStyle = 'rgba(17, 94, 89, 0.8)';
      });
    }

    function processDetections(output) {
      if (!videoWidth || !videoHeight) return;
      const scaleX = displayWidth / videoWidth;
      const scaleY = displayHeight / videoHeight;
      const [boxes, scores, classes, validDetections] = output.map(t => t.arraySync());
      const detections = [];
      for (let i = 0; i < validDetections[0]; i++) {
        const [y1, x1, y2, x2] = boxes[0][i];
        const inputX1 = x1 * TARGET - padLeft;
        const inputY1 = y1 * TARGET - padTop;
        const inputX2 = x2 * TARGET - padLeft;
        const inputY2 = y2 * TARGET - padTop;

        const videoX1 = Math.max(0, inputX1 / inputScale);
        const videoY1 = Math.max(0, inputY1 / inputScale);
        const videoX2 = Math.min(videoWidth, inputX2 / inputScale);
        const videoY2 = Math.min(videoHeight, inputY2 / inputScale);

        const width = Math.max(0, videoX2 - videoX1) * scaleX;
        const height = Math.max(0, videoY2 - videoY1) * scaleY;
        const x = videoX1 * scaleX;
        const y = videoY1 * scaleY;
        detections.push([x, y, width, height, scores[0][i], classes[0][i]]);
      }
      drawDetections(detections);
      output.forEach(t => t.dispose());
    }

    async function renderLoop() {
      if (!model || !video.srcObject) return;
      updateVideoMetrics();
      const canvasChanged = syncCanvasToVideo();
      if (!displayWidth || !displayHeight || !videoWidth || !videoHeight) {
        rafId = requestAnimationFrame(renderLoop);
        return;
      }
      if (canvasChanged) {
        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);
      }
      rafId = requestAnimationFrame(renderLoop);
      const input = preprocessFrame();
      const result = await model.executeAsync(input);
      processDetections(result);
      input.dispose();
    }

    startBtn.addEventListener('click', startDetection);
    stopBtn.addEventListener('click', stopDetection);
    video.addEventListener('loadedmetadata', () => {
      updateVideoMetrics();
      syncCanvasToVideo();
    });
    window.addEventListener('resize', syncCanvasToVideo);

    window.addEventListener('beforeunload', stopDetection);
    setStatus('loading');
    loadModel();

    document.addEventListener('language:change', () => setStatus(statusKey, statusState));
  });
</script>
